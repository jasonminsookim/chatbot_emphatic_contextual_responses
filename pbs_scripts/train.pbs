#!/bin/bash -l
# Name your job (used in the PBS output file names)
#PBS -N train_test
# Specify the gpuq queue
#PBS -q gpuq
# Specify the number of gpus
#PBS -l nodes=4:ppn=1
#PBS -l gpus=2
# Specify the gpu feature
#PBS -l feature=gpu
# Specify your resource account (use qr command to determine)
#PBS -A f002bhw
# Specify how much time you think the job will run
#PBS -l walltime=00:35:00

# specify your email aaddress
#PBS -M Jason.M.Kim.Gr@dartmouth.edu

source activate hpc_gpu_nlp
# Join error and standard output into one file
#PBS -j oe

#PBS -m ea

# Change to the directory that the job was submitted from
cd $PBS_O_WORKDIR

cd ../transfer-learning-conv-ai

# Parse the PBS_GPUFILE to determine which GPU you have been assigned
# and unset CUDA_VISIBLE_DEVICES
gpuNum=`cat $PBS_GPUFILE | sed -e 's/.*-gpu//g'`
unset CUDA_VISIBLE_DEVICES
# if using PyCUDA set the CUDA_DEVICE environment variable
export CUDA_DEVICE=$gpuNum
# Pass the GPU number as an argument to your program
python3 -m torch.distributed.launch --nproc_per_node=2 train.py

exit 0